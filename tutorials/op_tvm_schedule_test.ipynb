{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f2fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d88ec885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75257c80",
   "metadata": {},
   "source": [
    "# 循環優化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13fbd0d",
   "metadata": {},
   "source": [
    "## Loop unroll 循環展開"
   ]
  },
  {
   "cell_type": "raw",
   "id": "530b5056",
   "metadata": {},
   "source": [
    "循環展開（Loop Unrolling）\n",
    "循環展開是用於降低循環開銷的編譯器優化技術。循環展開將程序中的循環部分或全部展開，產生大量程序指令如圖3.4，減少循環次數從而降低指令分支預測的開銷。當程序中存在大量循環結構時，每一次循環迭代都要判斷是否滿足循環的條件，造成額外開銷。\n",
    "\n",
    "如果循環的次數已知，且數據前後沒有依賴關係，則可以產生大量指令針對每個數據進行運算，為具有多個功能單元的處理器提供指令級並行，也有利指令流水線的調度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b1abd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = tvm.te.var(\"n\")\n",
    "A = tvm.te.placeholder((n, n), name='A')\n",
    "B = tvm.te.placeholder((n, n), name='B')\n",
    "C = tvm.te.compute((n, n), lambda i, j: A[i, j] + B[i, j], name='C')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "908a8fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tvm.te.create_schedule(C.op)\n",
    "xo, xi = s[C].split(s[C].op.axis[0], factor=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69abad99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        stride_1 = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n, n), strides=(stride, stride_1), type=\"auto\")\n",
      "        stride_2 = T.int32()\n",
      "        stride_3 = T.int32()\n",
      "        B_1 = T.match_buffer(B, (n, n), strides=(stride_2, stride_3), type=\"auto\")\n",
      "        stride_4 = T.int32()\n",
      "        stride_5 = T.int32()\n",
      "        C_1 = T.match_buffer(C, (n, n), strides=(stride_4, stride_5), type=\"auto\")\n",
      "        for i_outer, i_inner in T.grid((n + 3) // 4, 4):\n",
      "            if T.likely(i_outer * 4 + i_inner < n):\n",
      "                for j in range(n):\n",
      "                    cse_var_1: T.int32 = i_outer * 4 + i_inner\n",
      "                    C_2 = T.Buffer((stride_4 * n,), data=C_1.data, type=\"auto\")\n",
      "                    A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "                    B_2 = T.Buffer((stride_2 * n,), data=B_1.data, type=\"auto\")\n",
      "                    C_2[cse_var_1 * stride_4 + j * stride_5] = A_2[cse_var_1 * stride + j * stride_1] + B_2[cse_var_1 * stride_2 + j * stride_3]\n",
      "---------cutting line---------\n"
     ]
    }
   ],
   "source": [
    "print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
    "print(\"---------Loop unroll---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0413bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        stride_1 = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n, n), strides=(stride, stride_1), type=\"auto\")\n",
      "        stride_2 = T.int32()\n",
      "        stride_3 = T.int32()\n",
      "        B_1 = T.match_buffer(B, (n, n), strides=(stride_2, stride_3), type=\"auto\")\n",
      "        stride_4 = T.int32()\n",
      "        stride_5 = T.int32()\n",
      "        C_1 = T.match_buffer(C, (n, n), strides=(stride_4, stride_5), type=\"auto\")\n",
      "        for i_outer in range((n + 3) // 4):\n",
      "            C_2 = T.Buffer((stride_4 * n,), data=C_1.data, type=\"auto\")\n",
      "            A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "            B_2 = T.Buffer((stride_2 * n,), data=B_1.data, type=\"auto\")\n",
      "            if T.likely(i_outer * 4 < n):\n",
      "                for j in range(n):\n",
      "                    cse_var_1: T.int32 = i_outer * 4\n",
      "                    C_2[cse_var_1 * stride_4 + j * stride_5] = A_2[cse_var_1 * stride + j * stride_1] + B_2[cse_var_1 * stride_2 + j * stride_3]\n",
      "            if T.likely(i_outer * 4 + 1 < n):\n",
      "                for j in range(n):\n",
      "                    cse_var_2: T.int32 = i_outer * 4 + 1\n",
      "                    C_2[cse_var_2 * stride_4 + j * stride_5] = A_2[cse_var_2 * stride + j * stride_1] + B_2[cse_var_2 * stride_2 + j * stride_3]\n",
      "            if T.likely(i_outer * 4 + 2 < n):\n",
      "                for j in range(n):\n",
      "                    cse_var_3: T.int32 = i_outer * 4 + 2\n",
      "                    C_2[cse_var_3 * stride_4 + j * stride_5] = A_2[cse_var_3 * stride + j * stride_1] + B_2[cse_var_3 * stride_2 + j * stride_3]\n",
      "            if T.likely(i_outer * 4 + 3 < n):\n",
      "                for j in range(n):\n",
      "                    cse_var_4: T.int32 = i_outer * 4 + 3\n",
      "                    C_2[cse_var_4 * stride_4 + j * stride_5] = A_2[cse_var_4 * stride + j * stride_1] + B_2[cse_var_4 * stride_2 + j * stride_3]\n"
     ]
    }
   ],
   "source": [
    "s[C].unroll(xi)\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6820ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3814f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf3601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f7a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0a1545c",
   "metadata": {},
   "source": [
    "## Loop Tiling(循環分塊)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa07fa55",
   "metadata": {},
   "source": [
    "循環分塊（Loop Tiling）\n",
    "循環分塊是利用cache的數據局部性進行優化的一種方法。現代CPU通常具有多級cache，在記憶體結構中，cache是除CPU寄存器外最接近CPU的存儲層次，相比主記憶體速度更快，但是容量更小。cache中複製了CPU頻繁使用的數據，所以CPU可以進行快速訪問。由於cache的容量有限，數據會在cache中進行換入換出。當訪問的數據在cache中沒有時，產生cache miss，會向低一級存儲層次發出訪問請求，然後該數據存儲進cache，這時訪問數據的時間就大大提高。當訪問數據就在cache中時，會直接使用該數據以進行復用。\n",
    "\n",
    "循環分塊主要針對大型數據集進行優化，大數據集無法一次全部存入cache中。當遍歷該數據集時，循環按照順序進行訪問，會替換掉之前加載進cache的數據，導致後面的指令對之前的數據無法復用，要重新加載數據，產生大量的cache miss，數據的復用性很差。程序執行時間變長，大量時間花費在載入數據上。\n",
    "\n",
    "循環分塊將大數據集分成多個小塊以充分進行數據復用。數據塊的內存訪問是一個具有高內存局部性的小鄰域。該數據塊可以一次加載進cache，執行完所有或者盡可能多的計算任務後才被替換出。原始的矩陣乘法存儲訪問模式和分塊後的存儲訪問模式見下圖1。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62b5b26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        stride_1 = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n, n), strides=(stride, stride_1), type=\"auto\")\n",
      "        stride_2 = T.int32()\n",
      "        stride_3 = T.int32()\n",
      "        B_1 = T.match_buffer(B, (n, n), strides=(stride_2, stride_3), type=\"auto\")\n",
      "        stride_4 = T.int32()\n",
      "        stride_5 = T.int32()\n",
      "        C_1 = T.match_buffer(C, (n, n), strides=(stride_4, stride_5), type=\"auto\")\n",
      "        for i, j in T.grid(n, n):\n",
      "            C_2 = T.Buffer((stride_4 * n,), data=C_1.data, type=\"auto\")\n",
      "            C_2[i * stride_4 + j * stride_5] = T.float32(0)\n",
      "            for K in range(n):\n",
      "                A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "                B_2 = T.Buffer((stride_2 * n,), data=B_1.data, type=\"auto\")\n",
      "                C_2[i * stride_4 + j * stride_5] = C_2[i * stride_4 + j * stride_5] + A_2[i * stride + K * stride_1] * B_2[K * stride_2 + j * stride_3]\n",
      "---------Loop Tiling---------\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "n = tvm.te.var(\"n\")\n",
    "A = tvm.te.placeholder((n, n), name='A')\n",
    "B = tvm.te.placeholder((n, n), name='B')\n",
    "K = tvm.te.reduce_axis((0, n), name='K')\n",
    "C = tvm.te.compute((n, n), lambda i, j: tvm.te.sum(A[i, K] * B[K, j], axis=K), name='C')\n",
    "\n",
    "s = tvm.te.create_schedule(C.op)\n",
    "\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
    "print(\"---------Loop Tiling---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85ab5817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        stride_1 = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n, n), strides=(stride, stride_1), type=\"auto\")\n",
      "        stride_2 = T.int32()\n",
      "        stride_3 = T.int32()\n",
      "        B_1 = T.match_buffer(B, (n, n), strides=(stride_2, stride_3), type=\"auto\")\n",
      "        stride_4 = T.int32()\n",
      "        stride_5 = T.int32()\n",
      "        C_1 = T.match_buffer(C, (n, n), strides=(stride_4, stride_5), type=\"auto\")\n",
      "        for i_outer, j_outer, i_inner, j_inner in T.grid((n + 31) // 32, (n + 31) // 32, 32, 32):\n",
      "            C_2 = T.Buffer((stride_4 * n,), data=C_1.data, type=\"auto\")\n",
      "            if T.likely(i_outer * 32 + i_inner < n):\n",
      "                if T.likely(j_outer * 32 + j_inner < n):\n",
      "                    C_2[(i_outer * 32 + i_inner) * stride_4 + (j_outer * 32 + j_inner) * stride_5] = T.float32(0)\n",
      "            if T.likely(i_outer * 32 + i_inner < n):\n",
      "                if T.likely(j_outer * 32 + j_inner < n):\n",
      "                    for K in range(n):\n",
      "                        cse_var_2: T.int32 = j_outer * 32 + j_inner\n",
      "                        cse_var_1: T.int32 = i_outer * 32 + i_inner\n",
      "                        A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "                        B_2 = T.Buffer((stride_2 * n,), data=B_1.data, type=\"auto\")\n",
      "                        C_2[cse_var_1 * stride_4 + cse_var_2 * stride_5] = C_2[cse_var_1 * stride_4 + cse_var_2 * stride_5] + A_2[cse_var_1 * stride + K * stride_1] * B_2[K * stride_2 + cse_var_2 * stride_3]\n"
     ]
    }
   ],
   "source": [
    "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], 32, 32)\n",
    "\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684c0c5c",
   "metadata": {},
   "source": [
    "## Loop Reorder (循環重排)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "42c4fdd1",
   "metadata": {},
   "source": [
    "循環重排（Loop Reorder）\n",
    "循環重排序（reorder）是矩陣乘法常見的優化方式，特別是在CNN中卷積層的應用。在矩陣乘法計算中，B是逐列訪問的，在行優先的存儲模式下訪問模式很不友好。切換內層的循環順序可以使得所有元素按順序讀取和寫入。一次計算輸出的一行，得到的是中間結果，全部累加即可得到結果矩陣的一行最終結果，這種方式利用的是內存的空間局部性(spatial locality)。\n",
    "\n",
    "Loop Reorder藉由內外層循環重排，改善記體體的空間局部性，並最大限度地利用引入cache的數據。對循環進行重新排序，以最大程度減少跨布將訪問模式與記憶體中的數據儲存模式對齊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afddda08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02514896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        stride_1 = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n, n), strides=(stride, stride_1), type=\"auto\")\n",
      "        stride_2 = T.int32()\n",
      "        stride_3 = T.int32()\n",
      "        B_1 = T.match_buffer(B, (n, n), strides=(stride_2, stride_3), type=\"auto\")\n",
      "        C = T.allocate([n * n], \"float32\", \"global\")\n",
      "        for i_outer, i_inner in T.grid((n + 31) // 32, 32):\n",
      "            if T.likely(i_outer * 32 + i_inner < n):\n",
      "                for j_outer, j_inner in T.grid((n + 31) // 32, 32):\n",
      "                    if T.likely(j_outer * 32 + j_inner < n):\n",
      "                        cse_var_3: T.int32 = j_outer * 32\n",
      "                        cse_var_2: T.int32 = cse_var_3 + j_inner\n",
      "                        cse_var_1: T.int32 = i_outer * 32 + i_inner\n",
      "                        C_1 = T.Buffer((n * n,), data=C)\n",
      "                        A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "                        B_2 = T.Buffer((stride_2 * n,), data=B_1.data, type=\"auto\")\n",
      "                        C_1[cse_var_3 + cse_var_1 * n + j_inner] = A_2[cse_var_1 * stride + cse_var_2 * stride_1] + B_2[cse_var_1 * stride_2 + cse_var_2 * stride_3]\n",
      "-Loop Reorder ------\n"
     ]
    }
   ],
   "source": [
    "# 範例：：以矩陣乘法為例，M, N, K三維，往往是將K放在最外層可以最大程度利用局部性。\n",
    "n = tvm.te.var(\"n\")\n",
    "dtype = \"float32\"\n",
    "A = tvm.te.placeholder((n, n), dtype=dtype, name='A')\n",
    "B = tvm.te.placeholder((n, n), dtype=dtype, name='B')\n",
    "C = tvm.te.compute((n, n), lambda i, j: A[i,j] + B[i,j], name='C')\n",
    "\n",
    "s = tvm.te.create_schedule(C.op)\n",
    "xo, xi = s[C].split(s[C].op.axis[0], factor=32)\n",
    "yo, yi = s[C].split(s[C].op.axis[1], factor=32)\n",
    "print(tvm.lower(s, [A, B], simple_mode=True))\n",
    "print(\"-Loop Reorder ------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5021b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        stride_1 = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n, n), strides=(stride, stride_1), type=\"auto\")\n",
      "        stride_2 = T.int32()\n",
      "        stride_3 = T.int32()\n",
      "        B_1 = T.match_buffer(B, (n, n), strides=(stride_2, stride_3), type=\"auto\")\n",
      "        C = T.allocate([n * n], \"float32\", \"global\")\n",
      "        for i_outer, j_outer, j_inner in T.grid((n + 31) // 32, (n + 31) // 32, 32):\n",
      "            if T.likely(j_outer * 32 + j_inner < n):\n",
      "                for i_inner in range(32):\n",
      "                    if T.likely(i_outer * 32 + i_inner < n):\n",
      "                        cse_var_3: T.int32 = j_outer * 32\n",
      "                        cse_var_2: T.int32 = cse_var_3 + j_inner\n",
      "                        cse_var_1: T.int32 = i_outer * 32 + i_inner\n",
      "                        C_1 = T.Buffer((n * n,), data=C)\n",
      "                        A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "                        B_2 = T.Buffer((stride_2 * n,), data=B_1.data, type=\"auto\")\n",
      "                        C_1[cse_var_3 + cse_var_1 * n + j_inner] = A_2[cse_var_1 * stride + cse_var_2 * stride_1] + B_2[cse_var_1 * stride_2 + cse_var_2 * stride_3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s[C].reorder(xo, yo, yi, xi)\n",
    "\n",
    "print(tvm.lower(s, [A, B], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee527a09",
   "metadata": {},
   "source": [
    "## Loop Fusion (循環融合)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47e383",
   "metadata": {},
   "source": [
    "Loop Fusion是將相鄰或緊密間隔的循環融合在一起，減少循環開銷和增加計算密度可改善軟體流水線，數據結構的cache局部性增加\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f15a8565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.Buffer((1,), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n,), strides=(stride,), type=\"auto\")\n",
      "        B_1 = T.Buffer((1,), data=B.data)\n",
      "        B_1[0] = T.float32(0)\n",
      "        for k_outer, k_inner in T.grid((n + 31) // 32, 32):\n",
      "            if T.likely(k_outer * 32 + k_inner < n):\n",
      "                A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "                B_1[0] = B_1[0] + A_2[(k_outer * 32 + k_inner) * stride]\n",
      "---------Loop Fusion---------\n"
     ]
    }
   ],
   "source": [
    "n = tvm.te.var(\"n\")\n",
    "A = tvm.te.placeholder((n,), name='A')\n",
    "k = tvm.te.reduce_axis((0, n), name='k')\n",
    "\n",
    "B = tvm.te.compute((1,), lambda i: tvm.te.sum(A[k], axis=k), name='B')\n",
    "\n",
    "s = tvm.te.create_schedule(B.op)\n",
    "\n",
    "ko, ki = s[B].split(B.op.reduce_axis[0], factor=32)\n",
    "\n",
    "print(tvm.lower(s, [A, B], simple_mode=True))\n",
    "print(\"---------Loop Fusion---------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db1fa9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.Buffer((1,), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n,), strides=(stride,), type=\"auto\")\n",
      "        B_1 = T.Buffer((1,), data=B.data)\n",
      "        B_1[0] = T.float32(0)\n",
      "        for k_outer_k_inner_fused in range((n + 31) // 32 * 32):\n",
      "            if T.likely(k_outer_k_inner_fused < n):\n",
      "                A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "                B_1[0] = B_1[0] + A_2[k_outer_k_inner_fused * stride]\n"
     ]
    }
   ],
   "source": [
    "s[B].fuse(ko, ki)\n",
    "\n",
    "print(tvm.lower(s, [A, B], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece08e8c",
   "metadata": {},
   "source": [
    "## Loop Split (循環拆分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038cfffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loop Split主要是將循環分成多個循環，可以在有條件的循環中使用，分為無條件循環和含條件循環。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36d77d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例：上面程式碼是將條件判斷放在循環中，這樣執行循環時，每次都要判斷一次條件，所以可以將條件判斷和計算兩者拆開成兩個循環，這樣執行速度會比較快。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab4afcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.Buffer((1,), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n,), strides=(stride,), type=\"auto\")\n",
      "        B_1 = T.Buffer((1,), data=B.data)\n",
      "        B_1[0] = T.float32(0)\n",
      "        for k in range(n):\n",
      "            A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "            B_1[0] = B_1[0] + A_2[k * stride]\n",
      "---------Loop Split ---------\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "\n",
    "n = tvm.te.var(\"n\")\n",
    "A = tvm.te.placeholder((n,), name='A')\n",
    "k = tvm.te.reduce_axis((0, n), name='k')\n",
    "\n",
    "B = tvm.te.compute((1,), lambda i: tvm.te.sum(A[k], axis=k), name='B')\n",
    "\n",
    "s = tvm.te.create_schedule(B.op)\n",
    "\n",
    "print(tvm.lower(s, [A, B], simple_mode=True))\n",
    "\n",
    "print(\"---------Loop Split ---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56c22335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.Buffer((1,), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n,), strides=(stride,), type=\"auto\")\n",
      "        B_1 = T.Buffer((1,), data=B.data)\n",
      "        B_1[0] = T.float32(0)\n",
      "        for k_outer, k_inner in T.grid((n + 31) // 32, 32):\n",
      "            if T.likely(k_outer * 32 + k_inner < n):\n",
      "                A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "                B_1[0] = B_1[0] + A_2[(k_outer * 32 + k_inner) * stride]\n"
     ]
    }
   ],
   "source": [
    "ko, ki = s[B].split(B.op.reduce_axis[0], factor=32)\n",
    "\n",
    "print(tvm.lower(s, [A, B], simple_mode=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9cb0f1",
   "metadata": {},
   "source": [
    "# Instructions Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c3b7cf",
   "metadata": {},
   "source": [
    "## Vectorization (向量化)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b600a",
   "metadata": {},
   "source": [
    "向量化（Vectorization）\n",
    "向量化是一種數據級並行優化。向量化即「批量操作」，在計算機中常見執行模型是單指令多數據（SIMD，Single Instruction Multiple Data）。通過對批量數據同時進行相同計算以提高效率。向量體系結構獲取在存儲器中散布的數據集，將多個數據元素放在大型的順序寄存器堆疊(stack)即向量寄存器中，對整個寄存器進行操作從而同時計算了多個數據元素。向量本身可以容納不同大小數據，因此如果一個向量寄存器可以容納64個64 bit元素，那麼也可以容納128個32 bit元素或者512個8 bit元素。憑借這種硬體上的多樣性，向量化特別適合用於多媒體應用和科學計算。\n",
    "\n",
    "\n",
    "傳統的執行方式為單指令單數據（SISD，Single Instruction Single Data），硬體不支持並行計算。現代CPU幾乎都支持SIMD指令集，如Intel的SSE和AVX系列指令集。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a288c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        m = T.int32()\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        stride_1 = T.int32()\n",
      "        A_1 = T.match_buffer(A, (m, n), strides=(stride, stride_1), type=\"auto\")\n",
      "        stride_2 = T.int32()\n",
      "        stride_3 = T.int32()\n",
      "        B_1 = T.match_buffer(B, (m, n), strides=(stride_2, stride_3), type=\"auto\")\n",
      "        stride_4 = T.int32()\n",
      "        stride_5 = T.int32()\n",
      "        C_1 = T.match_buffer(C, (m, n), strides=(stride_4, stride_5), type=\"auto\")\n",
      "        for x_outer, y_outer, x_inner in T.grid((m + 31) // 32, (n + 31) // 32, 32):\n",
      "            if T.likely(x_outer * 32 + x_inner < m):\n",
      "                for y_inner in range(32):\n",
      "                    if T.likely(y_outer * 32 + y_inner < n):\n",
      "                        cse_var_2: T.int32 = y_outer * 32 + y_inner\n",
      "                        cse_var_1: T.int32 = x_outer * 32 + x_inner\n",
      "                        C_2 = T.Buffer((stride_4 * m,), data=C_1.data, type=\"auto\")\n",
      "                        A_2 = T.Buffer((stride * m,), data=A_1.data, type=\"auto\")\n",
      "                        B_2 = T.Buffer((stride_2 * m,), data=B_1.data, type=\"auto\")\n",
      "                        C_2[cse_var_1 * stride_4 + cse_var_2 * stride_5] = A_2[cse_var_1 * stride + cse_var_2 * stride_1] + B_2[cse_var_1 * stride_2 + cse_var_2 * stride_3]\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "import numpy\n",
    "import timeit\n",
    "\n",
    "M = tvm.te.var(\"m\")\n",
    "N = tvm.te.var(\"n\")\n",
    "A = tvm.te.placeholder((M, N), name='A')\n",
    "B = tvm.te.placeholder((M, N), name='B')\n",
    "C = tvm.te.compute(\n",
    "           (M, N),\n",
    "           lambda x, y: A[x, y] + B[x, y],\n",
    "           name='C')\n",
    "\n",
    "s = tvm.te.create_schedule(C.op)\n",
    "xo, yo, xi, yi = s[C].tile(C.op.axis[0], C.op.axis[1], 32, 32)\n",
    "\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))\n",
    "print(\"---------Vectorization---------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bce8b5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle, C: T.handle):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        m = T.int32()\n",
      "        n = T.int32()\n",
      "        stride = T.int32()\n",
      "        stride_1 = T.int32()\n",
      "        A_1 = T.match_buffer(A, (m, n), strides=(stride, stride_1), type=\"auto\")\n",
      "        stride_2 = T.int32()\n",
      "        stride_3 = T.int32()\n",
      "        B_1 = T.match_buffer(B, (m, n), strides=(stride_2, stride_3), type=\"auto\")\n",
      "        stride_4 = T.int32()\n",
      "        stride_5 = T.int32()\n",
      "        C_1 = T.match_buffer(C, (m, n), strides=(stride_4, stride_5), type=\"auto\")\n",
      "        for x_outer, y_outer, x_inner in T.grid((m + 31) // 32, (n + 31) // 32, 32):\n",
      "            if T.likely(x_outer * 32 + x_inner < m):\n",
      "                for y_inner_s in range(32):\n",
      "                    if T.likely(y_outer * 32 + y_inner_s < n):\n",
      "                        cse_var_2: T.int32 = y_outer * 32 + y_inner_s\n",
      "                        cse_var_1: T.int32 = x_outer * 32 + x_inner\n",
      "                        C_2 = T.Buffer((stride_4 * m,), data=C_1.data, type=\"auto\")\n",
      "                        A_2 = T.Buffer((stride * m,), data=A_1.data, type=\"auto\")\n",
      "                        B_2 = T.Buffer((stride_2 * m,), data=B_1.data, type=\"auto\")\n",
      "                        C_2[cse_var_1 * stride_4 + cse_var_2 * stride_5] = A_2[cse_var_1 * stride + cse_var_2 * stride_1] + B_2[cse_var_1 * stride_2 + cse_var_2 * stride_3]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s[C].vectorize(yi)\n",
    "\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776f9c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "091a5f4a",
   "metadata": {},
   "source": [
    "## Tensorization (張量化）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b03c2",
   "metadata": {},
   "source": [
    "主流 CPU/GPU 硬件廠商都提供了專門角於張量化計算的張量指令，如英偉達的張量核指令、英特爾的VN。利用張量指令的一種方法是調用硬件廠商提供的算子庫，如英偉達的 cuBLAS 和 cDNN， 以及英特爾的 oneDNN 等。\n",
    "\n",
    "然而，當模型中出現新的算子或需要進—步提高性能時，這種方法的局限性便顯露無遺。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "dc98d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te\n",
    "import tvm.testing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f2bf921d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer((1024, 64), \"float32\"), B: T.Buffer((512, 64), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        for i, j in T.grid(1024, 512):\n",
      "            C_1 = T.Buffer((524288,), data=C.data)\n",
      "            C_1[i * 512 + j] = T.float32(0)\n",
      "            for k in range(64):\n",
      "                cse_var_1: T.int32 = i * 512 + j\n",
      "                A_1 = T.Buffer((65536,), data=A.data)\n",
      "                B_1 = T.Buffer((32768,), data=B.data)\n",
      "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[i * 64 + k] * B_1[j * 64 + k]\n"
     ]
    }
   ],
   "source": [
    "N, M, L = 1024, 512, 64\n",
    "A = te.placeholder((N, L), name=\"A\")\n",
    "B = te.placeholder((M, L), name=\"B\")\n",
    "k = te.reduce_axis((0, L), name=\"k\")\n",
    "C = te.compute((N, M), lambda i, j: te.sum(A[i, k] * B[j, k], axis=k), name=\"C\")\n",
    "s = te.create_schedule(C.op)\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "14956b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer((1024, 64), \"float32\"), B: T.Buffer((512, 64), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        for i, j_outer, j_inner in T.grid(1024, 32, 16):\n",
      "            C_1 = T.Buffer((524288,), data=C.data)\n",
      "            C_1[i * 512 + j_outer * 16 + j_inner] = T.float32(0)\n",
      "            for k in range(64):\n",
      "                cse_var_1: T.int32 = i * 512 + j_outer * 16 + j_inner\n",
      "                A_1 = T.Buffer((65536,), data=A.data)\n",
      "                B_1 = T.Buffer((32768,), data=B.data)\n",
      "                C_1[cse_var_1] = C_1[cse_var_1] + A_1[i * 64 + k] * B_1[j_outer * 1024 + j_inner * 64 + k]\n"
     ]
    }
   ],
   "source": [
    "factor = 16\n",
    "x, y = C.op.axis\n",
    "(z,) = C.op.reduce_axis\n",
    "yo, yi = s[C].split(y, factor=factor)\n",
    "s[C].reorder(x, yo, yi, z)\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "67cd9c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intrin_gemv(m, l):\n",
    "    a = te.placeholder((l,), name=\"a\")\n",
    "    b = te.placeholder((m, l), name=\"b\")\n",
    "    k = te.reduce_axis((0, l), name=\"k\")\n",
    "    c = te.compute((m,), lambda i: te.sum(a[k] * b[i, k], axis=k), name=\"c\")\n",
    "    Ab = tvm.tir.decl_buffer(a.shape, a.dtype, name=\"A\", offset_factor=1, strides=[1])\n",
    "    Bb = tvm.tir.decl_buffer(b.shape, b.dtype, name=\"B\", offset_factor=1, strides=[te.var(\"s1\"), 1])\n",
    "    Cb = tvm.tir.decl_buffer(c.shape, c.dtype, name=\"C\", offset_factor=1, strides=[1])\n",
    "\n",
    "    def intrin_func(ins, outs):\n",
    "        ib = tvm.tir.ir_builder.create()\n",
    "        aa, bb = ins\n",
    "        cc = outs[0]\n",
    "        ib.emit(\n",
    "            tvm.tir.call_extern(\n",
    "                \"int32\",\n",
    "                \"gemv_update\",\n",
    "                cc.access_ptr(\"w\"),\n",
    "                aa.access_ptr(\"r\"),\n",
    "                bb.access_ptr(\"r\"),\n",
    "                m,\n",
    "                l,\n",
    "                bb.strides[0],\n",
    "            )\n",
    "        )\n",
    "        return ib.get()\n",
    "\n",
    "    return te.decl_tensor_intrin(c.op, intrin_func, binds={a: Ab, b: Bb, c: Cb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8c0d8b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Tensorization----\n",
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.Buffer((1024, 64), \"float32\"), B: T.Buffer((512, 64), \"float32\"), C: T.Buffer((1024, 512), \"float32\")):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        for i, j_outer in T.grid(1024, 32):\n",
      "            T.call_extern(\"int32\", \"gemv_update\", T.tvm_access_ptr(T.type_annotation(\"float32\"), C.data, i * 512 + j_outer * 16, 16, 2), T.tvm_access_ptr(T.type_annotation(\"float32\"), A.data, i * 64, 64, 1), T.tvm_access_ptr(T.type_annotation(\"float32\"), B.data, j_outer * 1024, 1024, 1), 16, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "print(\"----Tensorization----\")\n",
    "gemv = intrin_gemv(factor, L)\n",
    "s[C].tensorize(yi, gemv)\n",
    "print(tvm.lower(s, [A, B, C], simple_mode=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed3bd5",
   "metadata": {},
   "source": [
    "# parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dfe64e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        m = T.int32()\n",
      "        stride = T.int32()\n",
      "        stride_1 = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n, m), strides=(stride, stride_1), type=\"auto\")\n",
      "        stride_2 = T.int32()\n",
      "        B_1 = T.match_buffer(B, (n,), strides=(stride_2,), type=\"auto\")\n",
      "        for i in range(n):\n",
      "            B_2 = T.Buffer((stride_2 * n,), data=B_1.data, type=\"auto\")\n",
      "            B_2[i * stride_2] = T.float32(0)\n",
      "            for l in range(m):\n",
      "                A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "                B_2[i * stride_2] = B_2[i * stride_2] + A_2[i * stride + l * stride_1]\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "n = 1024\n",
    "m = 1024\n",
    "n = tvm.te.var(\"n\")\n",
    "m = tvm.te.var(\"m\")\n",
    "\n",
    "A = tvm.te.placeholder((n, m), name='A')\n",
    "l = tvm.te.reduce_axis((0, m), name = 'l')\n",
    "\n",
    "B = tvm.te.compute((n,), lambda i: tvm.te.sum(A[i, l], axis=l), name='B')\n",
    "\n",
    "s = tvm.te.create_schedule(B.op)\n",
    "\n",
    "print(tvm.lower(s, [A, B], simple_mode=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c0bdb7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------parallel---------\n",
      "# from tvm.script import ir as I\n",
      "# from tvm.script import tir as T\n",
      "\n",
      "@I.ir_module\n",
      "class Module:\n",
      "    @T.prim_func\n",
      "    def main(A: T.handle, B: T.handle):\n",
      "        T.func_attr({\"from_legacy_te_schedule\": True, \"global_symbol\": \"main\", \"tir.noalias\": True})\n",
      "        n = T.int32()\n",
      "        m = T.int32()\n",
      "        stride = T.int32()\n",
      "        stride_1 = T.int32()\n",
      "        A_1 = T.match_buffer(A, (n, m), strides=(stride, stride_1), type=\"auto\")\n",
      "        stride_2 = T.int32()\n",
      "        B_1 = T.match_buffer(B, (n,), strides=(stride_2,), type=\"auto\")\n",
      "        for i in range(n):\n",
      "            B_2 = T.Buffer((stride_2 * n,), data=B_1.data, type=\"auto\")\n",
      "            B_2[i * stride_2] = T.float32(0)\n",
      "            for l in T.parallel(m):\n",
      "                A_2 = T.Buffer((stride * n,), data=A_1.data, type=\"auto\")\n",
      "                B_2[i * stride_2] = B_2[i * stride_2] + A_2[i * stride + l * stride_1]\n"
     ]
    }
   ],
   "source": [
    "print(\"---------parallel---------\")\n",
    "\n",
    "s[B].parallel(B.op.reduce_axis[0])\n",
    "print(tvm.lower(s, [A, B], simple_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09c727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c67652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d7bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.398px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
